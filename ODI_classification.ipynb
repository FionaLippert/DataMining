{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from inspect import getmembers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pd.read_csv('ODI-2018_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the discretized version of the money feature\n",
    "db['moneyBins'] = pd.qcut(db['money'], 3, np.arange(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AI', 'BA', 'Bioinformatics', 'CLS', 'CS', 'Drug Discovery and Safety', 'Duisenberg Honor Programme', 'EOR', 'Economics', 'Exchange', 'Finance', 'Human Movement Science', 'MPA', 'Mathematics', 'PhD student', 'Physics', 'QRM', 'SBI']\n",
      "['no', 'yes']\n",
      "['no', 'yes']\n",
      "[0, 1, 2]\n",
      "['no', 'yes']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(204, 25)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try different feature sets\n",
    "features1 = ['programme','DB','y_birth']\n",
    "features2 = ['programme','DB','stat','gender']\n",
    "features3 = ['programme','DB','IR','moneyBins']\n",
    "target = 'ML'\n",
    "\n",
    "features = features3\n",
    "\n",
    "# drop rows where selected features are missing\n",
    "columns = np.append(features, target)\n",
    "classification_data = pd.DataFrame(db[columns].replace(missing_data, np.nan).dropna(), columns=columns)\n",
    "\n",
    "# transform features to numerical categories\n",
    "le = preprocessing.LabelEncoder()\n",
    "for c in columns:\n",
    "    classification_data[c] = le.fit_transform(classification_data[c])\n",
    "    print(list(le.classes_))\n",
    "    \n",
    "# encode categorial features as multiple binary features\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "binary_features = enc.fit_transform(classification_data[features])\n",
    "binary_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7210776942355889 0.7179461152882206 0.7224849624060152 0.768032581453634\n"
     ]
    }
   ],
   "source": [
    "# perform 10-times repeated 10-fold cross-validation\n",
    "#cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=np.arange(10))\n",
    "dt_scores, rf_scores, rf200_scores, lr_scores = [], [], [], []\n",
    "\n",
    "for run in range(10):\n",
    "    cv = StratifiedKFold(n_splits=10, random_state=run)\n",
    "\n",
    "    dt_scores.extend(cross_val_score(DecisionTreeClassifier(random_state=run), binary_features, classification_data[target], cv=cv))\n",
    "    rf_scores.extend(cross_val_score(RandomForestClassifier(random_state=run), binary_features, classification_data[target], cv=cv))\n",
    "    rf200_scores.extend(cross_val_score(RandomForestClassifier(random_state=run, n_estimators=200), binary_features, classification_data[target], cv=cv))\n",
    "    lr_scores.extend(cross_val_score(LogisticRegression(), binary_features, classification_data[target], cv=cv))\n",
    "    \n",
    "print(np.mean(dt_scores), np.mean(rf_scores), np.mean(rf200_scores), np.mean(lr_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare dt and rf:  WilcoxonResult(statistic=661.0, pvalue=0.1877210029546681)\n",
      "compare dt and lr:  WilcoxonResult(statistic=510.0, pvalue=4.293578279619104e-07)\n",
      "compare rf and lr:  WilcoxonResult(statistic=292.0, pvalue=3.3590963679710135e-09)\n",
      "compare rf and rf200:  WilcoxonResult(statistic=731.5, pvalue=0.24536743657730342)\n",
      "compare dt and rf200:  WilcoxonResult(statistic=920.0, pvalue=0.6911152048437503)\n",
      "compare lr and rf200:  WilcoxonResult(statistic=195.0, pvalue=3.3639202733373324e-09)\n"
     ]
    }
   ],
   "source": [
    "print('compare dt and rf: ', scipy.stats.wilcoxon(dt_scores,rf_scores))\n",
    "print('compare dt and lr: ', scipy.stats.wilcoxon(dt_scores,lr_scores))\n",
    "print('compare rf and lr: ', scipy.stats.wilcoxon(rf_scores,lr_scores))\n",
    "print('compare rf and rf200: ', scipy.stats.wilcoxon(rf_scores,rf200_scores))\n",
    "print('compare dt and rf200: ', scipy.stats.wilcoxon(dt_scores,rf200_scores))\n",
    "print('compare lr and rf200: ', scipy.stats.wilcoxon(rf200_scores,lr_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8382352941176471"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_full_dataset = DecisionTreeClassifier(random_state=0).fit(binary_features, classification_data[target])\n",
    "dt_prediction_train = dt_full_dataset.predict(binary_features)\n",
    "print(dt_full_dataset.tree_.node_count, dt_full_dataset.tree_.max_depth)\n",
    "accuracy_score(dt_prediction_train, classification_data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 9, 11, 9, 11, 11, 17, 12, 14, 12] 17 9 11.6\n",
      "[79, 77, 79, 85, 83, 77, 87, 77, 87, 73] 87 73 80.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8382352941176471"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_full_dataset = RandomForestClassifier(random_state=0).fit(binary_features, classification_data[target])\n",
    "rf_prediction_train = rf_full_dataset.predict(binary_features)\n",
    "depths = [t.tree_.max_depth for t in rf_full_dataset.estimators_]\n",
    "print(depths, np.max(depths), np.min(depths), np.mean(depths))\n",
    "nodes = [t.tree_.node_count for t in rf_full_dataset.estimators_]\n",
    "print(nodes, np.max(nodes), np.min(nodes), np.mean(nodes))\n",
    "accuracy_score(rf_prediction_train, classification_data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 9 12.805\n",
      "111 65 87.42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8382352941176471"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf200_full_dataset = RandomForestClassifier(random_state=0,n_estimators=200).fit(binary_features, classification_data[target])\n",
    "rf200_prediction_train = rf200_full_dataset.predict(binary_features)\n",
    "depths = [t.tree_.max_depth for t in rf200_full_dataset.estimators_]\n",
    "print(np.max(depths), np.min(depths), np.mean(depths))\n",
    "nodes = [t.tree_.node_count for t in rf200_full_dataset.estimators_]\n",
    "print(np.max(nodes), np.min(nodes), np.mean(nodes))\n",
    "accuracy_score(rf200_prediction_train, classification_data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7843137254901961"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_full_dataset = LogisticRegression().fit(binary_features, classification_data[target])\n",
    "lr_prediction_train = lr_full_dataset.predict(binary_features)\n",
    "accuracy_score(lr_prediction_train, classification_data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
